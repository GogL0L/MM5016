#+title: Project 1
#+description: 
#+PROPERTY: header-args :tangle ./project1.py :padline 2
* Head
#+begin_src python :results output :session
from math import sqrt, sin,  cos, pi, exp
import numpy as np
import matplotlib.pyplot as plt
#+end_src

#+RESULTS:


* Code for submethods

** Statitstics

*** Average
#+begin_src python :results output :session
def average(data_set):
    """ Given a list of data [a1, a2, a3, ..., an], this returns
    the average given by (a1 + a2 + a3 + ... + an) / n.
    """
    n = len(data_set)
    return sum(data_set) / n
#+end_src

#+RESULTS:



*** Standard deviation
#+begin_src python :results output :session
def standard_deviation(estimated_data, correct_data):
    """ Given estimated_data = [e1, e2, e3, ..., en] and
    correct_data = [c1, c2, c3, ..., cn], this returns the
    squareroot of the variance, i.e. 
    (((e1 - c1)^2 + (e2 - c2)^2 + ... + (en - cn)^2) / n)^0.5.
    """
    n = len(estimated_data)
    differences = [estimated_data[i] - correct_data[i] for i in range(n)]
    differences_squared = list(map(lambda x: x ** 2, differences))
    return sqrt(average(differences_squared))
#+end_src

#+RESULTS:

**** test
#+begin_src python :results output :session :tangle no
edata = [4, -4, 2, 2]
cdata = [0, 0, 0, 1]
print(standard_deviation(edata, cdata))
#+end_src

#+RESULTS:
: 3.0413812651491097



*** Biggest error
#+begin_src python :results output :session
def biggest_error(estimated_data, correct_data):
    """ Returns the biggest error difference between an estimated
    data point and its correct value.
    """
    n = len(estimated_data)
    differences = [estimated_data[i] - correct_data[i] for i in range(n)]
    differences_abs = [abs(differences[i]) for i in range(n)]
    return max(differences_abs)
    
#+end_src

#+RESULTS:

**** test
#+begin_src python :results output :session :tangle no
edata = [-4, 4, 2, 2]
cdata = [0, 0, 0, -5]
big = biggest_error(edata, cdata)
print(big)
#+end_src

#+RESULTS:
: 7



** ODE solvers

*** Runge-Kutta

#+begin_src python :results output :session
def runge_kutta_method(derivative, initial_value, stepsize):
    """ Given that 'derivative' is a function of (x,y)
    and that the 'initial_value' is a tuple of the form
    (x0, y(x0)), this method returns a function that
    approximates y using runge kutta method in the equation 
    dy/dx = derivative(x,y).
    """


    def y(x):
        x0, y0 = initial_value
        xk, yk = x0, y0
        while x0 <= xk < x:
            k1 = derivative(xk,yk)
            k2 = derivative(xk + stepsize / 2, yk + stepsize * k1 / 2)
            k3 = derivative(xk + stepsize / 2, yk + stepsize * k2 / 2)
            k4 = derivative(xk + stepsize, yk + stepsize * k3)
            x_next = xk + stepsize 
            y_next = yk + (1/6) * stepsize * (k1 + 2 * k2 + 2 * k3 + k4)
            xk, yk = x_next, y_next
        return yk

    
    return y
#+end_src

#+RESULTS:


**** test
#+begin_src python :results output :session :tangle no
f = runge_kutta_method(lambda x,y: y, (0,1), 0.01)
print(f(1))
print("yello")
#+end_src

#+RESULTS:
: 2.718281828234403
: yello




*** Heuns's method
#+begin_src python :results output :session
def heun_method(derivative, initial_value, stepsize):
    """ Given that 'derivative' is a function of (x,y)
    and that the 'initial_value' is a tuple of the form
    (x0, y(x0)), this method returns a function that
    approximates y using heun's method in the equation 
    dy/dx = derivative(x,y).
    """


    def y(x):
        x0, y0 = initial_value
        xk, yk = x0, y0
        while x0 <= xk < x:
            x_next = xk + stepsize 
            y_bar = yk + stepsize * derivative(xk,yk)
            y_next = yk + (stepsize / 2) * (derivative(xk, yk) +
                                            derivative(x_next, y_bar))
            xk, yk = x_next, y_next
        return yk

    
    return y
#+end_src

#+RESULTS:

**** test
#+begin_src python :results output :session :tangle no
f = heun_method(lambda x,y: y, (0,1), 0.1)
print(f(1))
print("yello")
#+end_src

#+RESULTS:
: 2.9990593355020874
: yello




*** Euler's method
#+begin_src python :results output :session
def euler_method(derivative, initial_value, stepsize):
    """ Given that 'derivative' is a function of (x,y)
    and that the 'initial_value' is a tuple of the form
    (x0, y(x0)), this method returns a function that
    approximates y in the equation dy/dx = derivative(x,y).
    """
    step_to_goal = lambda x, goal: x+stepsize if x < goal else x - stepsize
    y_next = lambda x, y, goal: (y + stepsize * derivative(x,y) if x < goal
                                 else y - stepsize * derivative(x,y) )


    def y(x):
        x0, y0 = initial_value
        xk, yk = x0, y0
        while x0 <= xk < x or x0 >= xk > x:
            xk = step_to_goal(xk, x)
            yk = y_next(xk, yk, x)
        return yk

    
    return y
#+end_src

#+RESULTS:

***** test
#+begin_src python :results output :session :tangle no
f = euler_method(lambda x,y: y, (0,1), 0.1)
print(f(1))
print("ello")
#+end_src

#+RESULTS:
: 2.33436821409
: ello




*** Problem 2 Adams-Bashforth

#+begin_src python :results output :session
## Problem 2: Adams-Bashforth
def bashforth_method(derivative, initial_value_orbit, stepsize):
    """ Given that 'derivative' is a function of (x,y) and that the 'initial_value' is a tuple of the form
    (x0, y(x0)), this method returns a function that
    approximates y using the Adams-Bashforth method in the equation 
    dy/dx = derivative(x,y).
    """


    def y(x):
        orbit = initial_value_orbit.copy()
        while 0 <= orbit[-1][0] < x:
            (x0,y0), (x1,y1) = orbit[-2:]
            x_next = x1 + stepsize 
            y_next = (y1 + (3/2) * stepsize * derivative(x1,y1)
                      - (1/2) * stepsize * derivative(x0,y0))
            orbit.append((x_next, y_next))
            
        return orbit[-1][1]

    
    return y

## To get the adams-Bashforth method:
problem_2_bashforth = bashforth_method(problem_2_derivative,
                                             problem_2_init_orbit,
                                             problem_2_stepsize)

#+end_src

#+RESULTS:

**** test
#+begin_src python :results output :session :tangle no
f = bashforth_method(problem_2_derivative ,problem_2_init_orbit, problem_2_stepsize)
g = problem_2_runge_kutta
print(f(4))
print(g(4))
print(len(problem_2_init_orbit))
#+end_src

#+RESULTS:



*** Problem 2 Adams-Moulton

#+begin_src python :results output :session
## Problem 2: Adams-Moulton
def moulton_method(derivative, initial_value_orbit, stepsize):
    """ Given that 'derivative' is a function of (x,y) and that the 'initial_value' is a tuple of the form
    (x0, y(x0)), this method returns a function that
    approximates y using the Adams-Moulton method in the equation 
    dy/dx = derivative(x,y).
    """


    def y(x):
        orbit = initial_value_orbit.copy()
        while 0 <= orbit[-1][0] < x:
            (x0,y0), (x1,y1) = orbit[-2:]
            euler = euler_method(derivative, (x1,y1), stepsize)
            x_next = x1 + stepsize 
            y_next_approx = euler(x_next)
            
            y_next = (y1 + stepsize * ( (5/12) * derivative(x_next, y_next_approx)
                                        + (2/3) * derivative(x1,y1)
                                        - (1/12) * derivative(x0, y0)))
            orbit.append((x_next, y_next))
            
        return orbit[-1][1]

    
    return y

## To get the Adams-Moulton method:
#f = trapezoidal_method( problem_2_derivative ,problem_2_init_orbit, problem_2_stepsize)
problem_2_moulton = moulton_method(problem_2_derivative,
                                   problem_2_init_orbit,
                                   problem_2_stepsize)
#+end_src

#+RESULTS:

**** test
#+begin_src python :results output :session :tangle no
f = moulton_method( problem_2_derivative, problem_2_init_orbit, problem_2_stepsize)
print(f(1))
#+end_src

#+RESULTS:


** Display chart
#+begin_src python :results output :session
def display_chart_comparison(title, y1_data, y1_label, y2_data, y2_label,
                             x_data_labels,
                             x_label, y_label):
    # data to plot
    n_groups = len(y1_data)
    # create plot
    fig, ax = plt.subplots()
    index = np.arange(n_groups)
    bar_width = 0.35
    opacity = 0.8

    rects1 = plt.bar(index, y1_data, bar_width,
    alpha=opacity,
    color='b',
    label=(y1_label))

    rects2 = plt.bar(index + bar_width, y2_data, bar_width,
    alpha=opacity,
    color='g',
    label=(y2_label))

    plt.xlabel(x_label)
    plt.ylabel(y_label)
    plt.title(title)
    plt.xticks(index + bar_width, x_data_labels)
    plt.legend()

    plt.tight_layout()
    plt.show()

#+end_src

#+RESULTS:

*** test
#+begin_src python :results output :session :tangle no
y1 = [1,2,3,4]
y2 = [5,6,7,8]
yo = ["först", "andra", "tredje","fjärde"]
display_chart_comparison("hello", y1, "y1", y2, "y2", yo, "x_label", "y_label")
#+end_src

#+RESULTS:


** Display
#+begin_src python :results output :session
def display_errors(ODE_function,
                   ODE_problem_string_representation,
                   ODE_solver,
                   ODE_solver_string_representation,
                   initial_value_orbit,
                   data_points_list,
                   interval,
                   analytic_function):
    """ Displays a graph of the error data using the ODE_solver on this
    ODE_function problem in the given interval for all the data points sizes. """
    (start, end) = interval
    interval_size = end - start
    step_size = lambda N: interval_size / N
    x_intervals = list(map(lambda N: np.linspace(start, end, N),
                           data_points_list))
    approximated_functions = list(map(
        lambda N: ODE_solver(ODE_function, initial_value_orbit, step_size(N)),
        data_points_list))
    y_intervals = [list(map(approximated_functions[i], x_intervals[i]))
                   for i in range(len(x_intervals))]

    correct_y_intervals = [list(map(analytic_function, x_intervals[i]))
                           for i in range(len(x_intervals))]
   
    x_labels = list(map(str, data_points_list))
    deviations = [standard_deviation(y_intervals[i], correct_y_intervals[i])
                  for i in range(len(y_intervals))]
    max_errors = [biggest_error(y_intervals[i], correct_y_intervals[i])
                  for i in range(len(y_intervals))]
    title = ('Error for approximating the solution to ' +
              ODE_problem_string_representation +
              ' using ' +
              ODE_solver_string_representation)

    display_chart_comparison(title, deviations, "standard deviation",
                             max_errors, "Biggest absolute value error.",
                             x_labels,
                             "Number of points", "Error")
#+end_src

#+RESULTS:

*** test
#+begin_src python :results output :session
display_errors(lambda x,y: 2 * x,
               "dy/dx = 2 * x",
               euler_method,
               "euler method",
               (0,0),
               [5,10,20],
               (0,1),
               lambda x: x ** 2)

#+end_src

#+RESULTS:



** Display graph
#+begin_src python :results output :session
def display_graph(x_data_list, y_data_list, y_data_labels,
                  x_axis_label, y_axis_label):
    """ Displays multiple functions in one graph. """
    n = len(x_data_list)
    for i in range(n):
        plt.plot(x_data_list[i], y_data_list[i], label=y_data_labels[i])
    plt.xlabel(x_axis_label)
    plt.ylabel(y_axis_label)

    plt.legend()
    plt.show()
#+end_src

#+RESULTS:

*** test
#+begin_src python :results output :session :tangle no
x = [[1,2,3,4],[0,2,0,4],[1,2,3]]
y = [[1,4,9,16],[0,2,0,4],[3,5,7]]
labels = ["squared", "linear", "linear offset"]
display_graph(x,y, labels, "x", "y")
#+end_src

#+RESULTS:

* Project 1 tasks

** Function
#+begin_src python :results output :session
def F(t,u):
    """ The function symbolising the second the derivative from
    the ODE for Project 1. I.e du/dt = cos(pi * t) + u(t).
    """
    return cos(pi * t) + u

F_label = "du/dt = cos(pi * t) + u(t)"
#+end_src

#+RESULTS:

*** test
#+begin_src python :results output :session :tangle no
print(F(1,2))
#+end_src

#+RESULTS:
: 1.0



** Analytic function
#+begin_src python :results output :session
analytic_solution = lambda t:( (pi * sin(pi*t))/(pi ** 2  + 1)
                               - (cos(pi*t))/(pi ** 2 + 1)
                               + ( 2 + 1/(pi **2 + 1) ) * exp(t)
                               )
#+end_src

#+RESULTS:

*** Test
#+begin_src python :results output :session :tangel no
print(analytic_solution(3))
#+end_src

#+RESULTS:
: 42.110936250298195



** N data points
#+begin_src python :results output :session
N = [10, 20, 40, 80, 160, 320, 640]
interval = (0,2)
#+end_src

#+RESULTS:


** task A (Euler's method)
#+begin_src python :results output :session
def task_a():
    """ Prints out the graph for the errors using Euler's method. """
    #display(F, euler_method, N, interval, analytic_function)
    display_errors(F,
               F_label,
               euler_method,
               "Euler's method",
               (0,2),
               N,
               (0,2),
               analytic_solution)
#+end_src

#+RESULTS:

*** test
#+begin_src python :results output :session :tangle no
task_a()
#+end_src

#+RESULTS:


** task B (Runge-Kutta second order)



** task C (Runge-Kutta fourth order)



** task D (Any multi-step method, in my case Adams-Bashforth)



