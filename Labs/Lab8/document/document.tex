% Created 2021-06-01 Tue 02:55
% Intended LaTeX compiler: pdflatex
\documentclass[10pt]{article}
     \usepackage{/home/john/texstuff/NoTeX/NotesTeXSW}
     \input{/home/john/skola/test/test3/bold.tex}
     \usepackage{minted}
\date{\today}
\title{MM5016 Laboration 8 Error analysis}
\hypersetup{
 pdfauthor={},
 pdftitle={MM5016 Laboration 8 Error analysis},
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 27.2 (Org mode 9.4.4)}, 
 pdflang={Samin}}
\begin{document}

\maketitle

\section{Problems}
\label{sec:org80cb0e5}

\begin{exercise}[1]  \label{exe:1}
The two quantities \(x\) and \(y\) have a relative error
of \(\epsilon_x\) respectively \(\epsilon_y\). Calculate the error in the following cases:
\begin{enumerate}
\item \(x -2y\)
\item \(4x -5y\)
\item \(3xy\)
\item \(x^{3} / y^{5}\)
\item \(\sqrt{x}\)
\item \(\sqrt{x^{3} }\)
\item \(\sqrt{2xy}\)
\item \(2 \sqrt{\frac{x}{3y}}\)
\item \(2 \sqrt{\frac{x^{3} }{3y}}\)
\item \(\frac{x}{y} + \frac{y}{x}\)
\item \(x^2 + y^2\)
\end{enumerate}
\end{exercise}
\begin{lemma}[error of scaled approximate value] \label{lem:error_of_scaled_approximate_value}
Let \(x\) be a value and \(\tilde{x}\) and approximation with relative error \(\epsilon _x\), and
\(\lambda\) a scalar. Then the relative error of \(\lambda \tilde{x}\) is
\(\epsilon _{\lambda x } = \epsilon _{x}\). This is because \(\lambda \tilde{x} = \lambda x(1+ \epsilon _{\lambda x} )\).
\end{lemma}
\begin{lemma}[error of exponent] \label{lem:error_of_exponent}
Let \(x\) be a value and \(\tilde{x}\) and approximation with relative
error \(\epsilon _{x}\), and \(a\) an integer. Then the relative error of
\(\tilde{x} ^{a}\) is \(\epsilon _{x^{a} } = a \epsilon _{x}\). This is because
\(\epsilon _{x^{a} } = \epsilon _{x x^{a-1} } = \epsilon _{x} + \epsilon _{x^{a-1} }\) .
\end{lemma}
\begin{solution}[1]  \label{sol:1}
(1)
\begin{align*}
\epsilon _{x - 2y} &   = \frac{x}{x - (2y) } \epsilon _{x} -
\frac{(2y) }{x - (2y) } \epsilon _{2y} \\
& = \frac{x}{x - 2 y } \epsilon _{x} -
\frac{2 y }{x - 2 y  } \epsilon _{y}
.
\end{align*}

(2)
\begin{align*}
\epsilon _{4x - 5y}  &  =
\frac{4x}{4x - 5y} \epsilon _{4x} - \frac{5y}{4x - 5y} \epsilon _{5y} \\
& = 
\frac{4x}{4x - 5y} \epsilon _{x} - \frac{5y}{4x - 5y} \epsilon _{y}
.
\end{align*}

(3)
\begin{align*}
\epsilon _{3xy} = \epsilon _{xy} = \epsilon _{x} + \epsilon _{y}
.
\end{align*}

(4)
\begin{align*}
\epsilon _{\frac{x^{3} }{y^{5} } } = \epsilon _{x^{3} } - \epsilon _{y^{5}} = 3 \epsilon _{x} - 5 \epsilon _{y}
.
\end{align*}

(5)
\begin{align*}
 &  \epsilon _{x} = \epsilon _{\sqrt{x}^{2}} = 2 \cdot\epsilon _{\sqrt{x}} \\
\implies & \epsilon _{\sqrt{x}} = \epsilon _{x} / 2
.
\end{align*}

(6)
\begin{align*}
\epsilon _{\sqrt{x^{3}}} = \frac{\epsilon _{x^{3}}}{2} = \frac{3}{2} \epsilon _{x}
.
\end{align*}
(7)
\begin{align*}
\epsilon _{\sqrt{2xy}}  &  = \epsilon _{\sqrt{2} \cdot  \sqrt{x} \cdot \sqrt{y}} \\
& = \epsilon _{\sqrt{x} \cdot  \sqrt{y}} = \epsilon _{\sqrt{x}} + \epsilon _{\sqrt{y}} \\
& = \frac{\epsilon _{x}}{2} + \frac{\epsilon _{y}}{2} 
.
\end{align*}

(7)
\begin{align*}
\epsilon _{2 \sqrt{ \frac{x^{3}}{3y}}}  &  = \epsilon _{\sqrt{ \frac{x^{3}}{3y}}}
= \frac{\epsilon _{\frac{x^{3}}{3y}}}{2} = \frac{\epsilon _{x^{3}} - \epsilon _{3y}}{2}
= \frac{3 \epsilon _{x} - \epsilon _{y}}{2} 
.
\end{align*}
(8)
\begin{align*}
\epsilon _{\frac{x}{y} + \frac{y}{x}}  &
= \frac{\frac{x}{y}}{\frac{x}{y} + \frac{y}{x}} \epsilon _{\frac{x}{y}}
+ \frac{\frac{y}{z}}{\frac{x}{y} + \frac{y}{x}} \epsilon _{\frac{y}{z}}
= \frac{x}{x + \frac{y ^2}{x}} \epsilon _{\frac{x}{y}}
+ \frac{y}{\frac{x}{yz} + \frac{y}{xz}} \epsilon _{\frac{y}{z}} \\
& = 
\frac{x}{x + \frac{y ^2}{x}} \epsilon _{\frac{x}{y}}
+ \frac{y}{\frac{x^2 + y ^2}{xyz}} \epsilon _{\frac{y}{z}} \\
& = 
\frac{x}{x + \frac{y ^2}{x}} \epsilon _{\frac{x}{y}}
+ \frac{x y ^2 z}{x^2 + y ^2} \epsilon _{\frac{y}{z}} \\
& = 
\frac{x ^2}{x ^2 + y ^2} \epsilon _{\frac{x}{y}}
+ \frac{x y ^2 z}{x^2 + y ^2} \epsilon _{\frac{y}{z}} \\
& =
\frac{x}{x ^2 + y ^2} (\epsilon _{\frac{x}{y}} + y ^2 z \epsilon _{\frac{y}{z}}) \\
& =
\frac{x}{x ^2 + y ^2} (\epsilon _{x} - \epsilon _{y} + y ^2 z (\epsilon _{y} - \epsilon _{z}))
.
\end{align*}

(8)
\begin{align*}
\epsilon _{x^2 + y^2}  &   = \frac{x ^2}{x^2 + y ^2} \epsilon _{x ^2} + \frac{y ^2}{x ^2 + y^2} \epsilon _{y ^2} \\
& = \frac{x ^2}{x^2 + y ^2} 2\epsilon _{x} + \frac{y ^2}{x ^2 + y^2} 2\epsilon _{y}
.
\end{align*}
\end{solution}
\begin{exercise}[2]  \label{exe:2}
The radius of a sphere is \(R = (22.2 \pm 0.1)cm\). The radius
of the base of a cylinder is \(r= (12.0 \pm 1.2)cm\), and its
height is \(h=(24.4 \pm 1.1)cm\). What is the total volum
occupied by the sphere and by the cylinder (including the error)?
\end{exercise}
\begin{solution}[2]  \label{sol:2}
Let the subscript \(t\) denote the true value.
\begin{align*}
V _{total}  &  = \frac{4 \pi}{3} (R + \delta R)^{3} + \pi (r+ \delta r) ^2 h \\
& = \frac{4 \pi}{3} (R^{3} + 3 R^2 \delta R + 3 R \delta R ^2 + \delta R^{3})
+ \pi (r ^2 + 2 \delta r+ \delta ^2) (h + \delta h) \\
& = \frac{4 \pi}{3} (R^{3} + 3 R^2 \delta R + 3 R \delta R ^2)
+ \pi (r ^2 + 2 \delta r) (h + \delta h) \\
& = \frac{4 \pi}{3} (R^{3} + 3 R^2 \delta R + 3 R \delta R ^2)
+ \pi (r ^2 h + r ^2 \delta h + 2 \delta h r + 2 \delta r \delta h) \\
& = \frac{4 \pi}{3} (R^{3} + 3 R^2 \delta R)
+ \pi (r ^2 h + r ^2 \delta h + 2r \delta h )
.
\end{align*}

To calculate the minimum volume we let the absolute be so much negative
as possible and the reverse for the maximum, if we plug in these values
we get:
\begin{align*}
55668.1 \leq V _{total} \leq 58068
.
\end{align*}


\end{solution}
\begin{exercise}[3]  \label{exe:3}
Suppose
\begin{align*}
F = \frac{P \pi a^{4} }{8lw} 
.
\end{align*}
Write down an expression for the maximum percentage error in \(F\). Suppose
further that \(\frac{\delta P}{P} = 0.5\%\), \(\frac{\delta a}{a} = 0.5 \%\), \(\frac{\delta l}{l} = 0.1\%\), and \(\frac{\delta w}{w} = 1\%\), calculate the
percent error in the result.
\end{exercise}
\begin{solution}[3]  \label{sol:3}
\begin{align*}
\epsilon _{F}  &  = \epsilon _{\frac{P \pi a^{4}}{8 l w}} = \epsilon _{\frac{P a^{4}}{ l w} }
= \epsilon _{P a^{4}} - \epsilon _{l w} = (\epsilon _{P} + \epsilon _{a^{4}}) - (\epsilon _{l} + \epsilon _{w}) \\
& = \epsilon _{P} + 4 \epsilon _{a} - \epsilon _{l} - \epsilon _{w} \\
& = 0.5 \% + 4 \cdot 0.5\% - 0.1 \% - 0.1 \% \\
& = 2.3 \%
.
\end{align*}

\end{solution}
\begin{exercise}[4]  \label{exe:4}
Solve the system
\begin{align*}
5x_1 + 7x_2 = b_1 \\
7x_1 + 10x_2 = b_2
,
\end{align*}
using Gaussian elimination method to obtain the solution \(x_1\)
when \(b _{T} = (b_1, b_2) = (0.7, 1)\). Also solve the above system
with \(b_A = (b_1, b_2) = (0.69, 1.01)\) using the same method to
obtain the solution \(x_2\). Show that
\end{exercise}
\begin{solution}[4]  \label{sol:4}
\textbf{Solving for \(x_1\)}:
\begin{align*}
5x_1 + 7x_2 = b_1 \\
7x_1 + 10x_2 = b_2
.
\end{align*}
Let us scale each row, so that the factors in \(x_1\) match:
\begin{align*}
35x_1 + 49x_2 = 7b_1 \\
35x_1 + 50x_2 = 5b_2
.
\end{align*}
Let's eliminate:
\begin{align*}
35x_1 + 49x_2 = 7b_2 \\
 x_2 = 5b_2 - 7b_1
.
\end{align*}
And let's substitute:
\begin{align*}
35x_1 + 245 b_2 - 343 b_1 = 7 b_2 \\
x_2 = 5b_2 - 7b_1
.
\end{align*}

Simpify:
\begin{align*}
x_1 = 10 b_1 - 7 b_2 \\
x_2 = 5b_2 - 7b_1
.
\end{align*}

We can then plugin the \(b_T\) or \(b_A\), to get the desired solution.
If we plugin \(b_T\) we get the solution (we will now transition from \(x_1\) and
\(x_2\) being numbers to vectors, specified by the correction in Discord):
\begin{align*}
x_1 =
\left( \begin{array}{c}
0 \\
0.1
\end{array} \right)
.
\end{align*}

and for \(b_A\) we get:
\begin{align*}
x_2 =
\left( \begin{array}{}
-0.17 \\
0.22
\end{array} \right)
.
\end{align*}

The equation is just a reformulation of the equation in the notes.

What follows is an alternative proof in case it is sufficent.

\textbf{Proving the inequality}:
First let us calculate the left hand side:
\begin{align*}
 &  \frac{\| x_1 - x_2 \| _{2}}{\| x_1 \| _{2}} \\
& = \frac{\sqrt{0.17 ^2 + 0.02 ^2}}{\sqrt{0.1 ^2}} \\
& = 10 \cdot \sqrt{0.0293}
.
\end{align*}


Let us now calculate the right hand side.
\(\| A \| _{2} \| A^{-1}  \| _{2}\) is the condition number. When A is normal, it can
be calculated by dividing the greatest eigenvalue magnitude with
the lowest magnitude . So let us
calculate the eigenvalues.
The charactheristic equation for \(A\) is
\begin{align*}
 &  (5- \lambda) (10 - \lambda) - 49 = 0 \\
\iff & \lambda ^2 - 15x + 1 = 0 \\
\iff & (\lambda - \frac{15}{2}) ^2  = \frac{15 ^2}{4}  -1 \\
\iff & (\lambda - \frac{15}{2}) ^2  = \frac{15 ^2 - 4}{4} \\
\iff & (\lambda - \frac{15}{2})  = \pm \frac{\sqrt{15 ^2 - 4}}{2} \\
\iff & \lambda  = \frac{15}{2} \pm \frac{\sqrt{15 ^2 - 4}}{2} \\
\iff & \lambda  =  \frac{15 \pm \sqrt{15 ^2 - 4}}{2} \\
\iff & \lambda  =  \frac{15 \pm \sqrt{221}}{2}
.
\end{align*}

So the greatest condition number is
\begin{align*}
 &  \frac{15 + \sqrt{221}}{15 - \sqrt{221}} \\
& = \frac{15 ^2 + 221 + 30 \sqrt{221}}{15 ^2 - 221} \\
& = \frac{223 + 15 \sqrt{221}}{2} 
.
\end{align*}


Let us now calculate the rest of the right hand side:

\begin{align*}
 &  \frac{\| b_T - b_A \| _{2}}{\| b_T \| _{2}} \\
& = \frac{\sqrt{0.01 ^2 + 0.01 ^2}}{\sqrt{0.7 ^2 + 1}} \\
& = \frac{\sqrt{0.0002}}{\sqrt{1.49}} 
.
\end{align*}

The inequality is thus equivalent to:
\begin{align*}
 &  10 \cdot \sqrt{0.0293} \leq \frac{1}{2} (223 + 15 \sqrt{221})\frac{\sqrt{0.0002}}{\sqrt{1.49}} \\
\iff &  20 \cdot \sqrt{0.0293} \leq (223 + 15 \sqrt{221})\frac{\sqrt{0.0002}}{\sqrt{1.49}} \\
\iff & \sqrt{400 \cdot 0.0293} \leq (223 + 15 \sqrt{221}) \sqrt{\frac{0.0002}{1.49} } \\
\iff & \sqrt{11.72} \leq (223 + 15 \sqrt{221}) \sqrt{\frac{1}{10^{4}} \cdot \frac{2}{1.49}} \\
\iff & \sqrt{11.72} \leq (223 + 15 \sqrt{221}) \frac{1}{10 ^2} \cdot \sqrt{\frac{2}{1.49}} \\
\iff & 10 ^2 \sqrt{11.72} \leq (223 + 15 \sqrt{221}) \cdot \sqrt{\frac{2}{1.49}} \\
\iff &  \sqrt{1172} \leq (223 + 15 \sqrt{221}) \cdot \sqrt{\frac{2}{1.49}} \\
\iff &  \sqrt{\frac{1.49 \cdot1172}{2}} \leq 223 + 15 \sqrt{221} \\
\iff &  \sqrt{873.14} \leq 223 + 15 \sqrt{221}
.
\end{align*}

Which is true, and thus the proof is done.
\end{solution}
\begin{exercise}[5]  \label{exe:5}
Show by an example that \(\| \cdot \| _{M}\) defined by
\(\| A \| _{M} = \max_{1\leq i,j \leq n} \| a _{ij} \|\) does not define an induced
matrix norm.
\end{exercise}
\begin{solution}[5]  \label{sol:5}
Assume \(\| \cdot \| _{M}\) is a norm.
Let
\begin{align*}
A =
\left( \begin{array}{c c}
1  &  3 \\
0  &  1 
\end{array} \right)
,
\end{align*}
and
\begin{align*}
B =
\left( \begin{array}{c c}
1  &  0 \\
3  &  1
\end{array} \right)
.
\end{align*}

Then
\begin{align*}
AB =
\left( \begin{array}{c c}
10  &  3 \\
3  &  1
\end{array} \right)
.
\end{align*}
Thus
\begin{align*}
\| A \| \| B \| = 9
\end{align*}
and
\begin{align*}
\| AB \| = 10
.
\end{align*}

Which means that
\begin{align*}
\| A \| \| B \| < \| AB \| 
.
\end{align*}
This is a contradiction for the rules about norms. The assumption
was thus wrong, and the proof is complete.
\end{solution}
\begin{exercise}[6]  \label{exe:6}
Show that \(\kappa(A) \geq 1\) for any non-singular matrix A.
\end{exercise}
\begin{solution}[6]  \label{sol:6}
Let us prove it for matrices of dimension two or higher.
Let \(A\) be a non singular matrix of dimension \(n\). That means there exists
\(n\) linearly independent eigenvectors, as otherwise the span of \(A\)
wouldn't be the whole room, and \(A\) would be singular. But from
linear algebra we know that each distinct eigenvector has it's own
eigen value, which are all distinct. Because they are distinct there exists
a largest one, let's call it \(\lambda\).
\end{solution}
\end{document}
